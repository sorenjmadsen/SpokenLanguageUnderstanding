{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fiqyOO_jd0V"
      },
      "source": [
        "Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5j-5fjGZ2UT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "@Author\t\t:           Lee, Qin\n",
        "@StartTime\t:           2018/08/13\n",
        "@Filename\t:           module.py\n",
        "@Software\t:           Pycharm\n",
        "@Framework  :           Pytorch\n",
        "@LastModify\t:           2019/05/07\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "\n",
        "\n",
        "class ModelManager(nn.Module):\n",
        "\n",
        "    def __init__(self, args, num_word, num_slot, num_intent):\n",
        "        super(ModelManager, self).__init__()\n",
        "\n",
        "        self.__num_word = num_word\n",
        "        self.__num_slot = num_slot\n",
        "        self.__num_intent = num_intent\n",
        "        self.__args = args\n",
        "\n",
        "        # Initialize an embedding object.\n",
        "        self.__embedding = EmbeddingCollection(\n",
        "            self.__num_word,\n",
        "            self.__args.word_embedding_dim\n",
        "        )\n",
        "\n",
        "        # Initialize an LSTM Encoder object.\n",
        "        self.__encoder = LSTMEncoder(\n",
        "            self.__args.word_embedding_dim,\n",
        "            self.__args.encoder_hidden_dim,\n",
        "            self.__args.dropout_rate\n",
        "        )\n",
        "\n",
        "        # Initialize an self-attention layer.\n",
        "        self.__attention = SelfAttention(\n",
        "            self.__args.word_embedding_dim,\n",
        "            self.__args.attention_hidden_dim,\n",
        "            self.__args.attention_output_dim,\n",
        "            self.__args.dropout_rate\n",
        "        )\n",
        "\n",
        "        # Initialize an Decoder object for intent.\n",
        "        self.__intent_decoder = LSTMDecoder(\n",
        "            self.__args.encoder_hidden_dim + self.__args.attention_output_dim,\n",
        "            self.__args.intent_decoder_hidden_dim,\n",
        "            self.__num_intent, self.__args.dropout_rate,\n",
        "            embedding_dim=self.__args.intent_embedding_dim\n",
        "        )\n",
        "        # Initialize an Decoder object for slot.\n",
        "        self.__slot_decoder = LSTMDecoder(\n",
        "            self.__args.encoder_hidden_dim + self.__args.attention_output_dim,\n",
        "            self.__args.slot_decoder_hidden_dim,\n",
        "            self.__num_slot, self.__args.dropout_rate,\n",
        "            embedding_dim=self.__args.slot_embedding_dim,\n",
        "            extra_dim=self.__num_intent\n",
        "        )\n",
        "\n",
        "        # One-hot encoding for augment data feed. \n",
        "        self.__intent_embedding = nn.Embedding(\n",
        "            self.__num_intent, self.__num_intent\n",
        "        )\n",
        "        self.__intent_embedding.weight.data = torch.eye(self.__num_intent)\n",
        "        self.__intent_embedding.weight.requires_grad = False\n",
        "\n",
        "    def show_summary(self):\n",
        "        \"\"\"\n",
        "        print the abstract of the defined model.\n",
        "        \"\"\"\n",
        "\n",
        "        print('Model parameters are listed as follows:\\n')\n",
        "\n",
        "        print('\\tnumber of word:                            {};'.format(self.__num_word))\n",
        "        print('\\tnumber of slot:                            {};'.format(self.__num_slot))\n",
        "        print('\\tnumber of intent:\t\t\t\t\t\t    {};'.format(self.__num_intent))\n",
        "        print('\\tword embedding dimension:\t\t\t\t    {};'.format(self.__args.word_embedding_dim))\n",
        "        print('\\tencoder hidden dimension:\t\t\t\t    {};'.format(self.__args.encoder_hidden_dim))\n",
        "        print('\\tdimension of intent embedding:\t\t    \t{};'.format(self.__args.intent_embedding_dim))\n",
        "        print('\\tdimension of slot embedding:\t\t\t    {};'.format(self.__args.slot_embedding_dim))\n",
        "        print('\\tdimension of slot decoder hidden:  \t    {};'.format(self.__args.slot_decoder_hidden_dim))\n",
        "        print('\\tdimension of intent decoder hidden:        {};'.format(self.__args.intent_decoder_hidden_dim))\n",
        "        print('\\thidden dimension of self-attention:        {};'.format(self.__args.attention_hidden_dim))\n",
        "        print('\\toutput dimension of self-attention:        {};'.format(self.__args.attention_output_dim))\n",
        "\n",
        "        print('\\nEnd of parameters show. Now training begins.\\n\\n')\n",
        "\n",
        "    def forward(self, text, seq_lens, n_predicts=None, forced_slot=None, forced_intent=None):\n",
        "        word_tensor, _ = self.__embedding(text)\n",
        "\n",
        "        lstm_hiddens = self.__encoder(word_tensor, seq_lens)\n",
        "        # transformer_hiddens = self.__transformer(pos_tensor, seq_lens)\n",
        "        attention_hiddens = self.__attention(word_tensor, seq_lens)\n",
        "        hiddens = torch.cat([attention_hiddens, lstm_hiddens], dim=1)\n",
        "\n",
        "        pred_intent = self.__intent_decoder(\n",
        "            hiddens, seq_lens,\n",
        "            forced_input=forced_intent\n",
        "        )\n",
        "\n",
        "        if not self.__args.differentiable:\n",
        "            _, idx_intent = pred_intent.topk(1, dim=-1)\n",
        "            feed_intent = self.__intent_embedding(idx_intent.squeeze(1))\n",
        "        else:\n",
        "            feed_intent = pred_intent\n",
        "\n",
        "        pred_slot = self.__slot_decoder(\n",
        "            hiddens, seq_lens,\n",
        "            forced_input=forced_slot,\n",
        "            extra_input=feed_intent\n",
        "        )\n",
        "\n",
        "        if n_predicts is None:\n",
        "            return F.log_softmax(pred_slot, dim=1), F.log_softmax(pred_intent, dim=1)\n",
        "        else:\n",
        "            _, slot_index = pred_slot.topk(n_predicts, dim=1)\n",
        "            _, intent_index = pred_intent.topk(n_predicts, dim=1)\n",
        "\n",
        "            return slot_index.cpu().data.numpy().tolist(), intent_index.cpu().data.numpy().tolist()\n",
        "\n",
        "    def golden_intent_predict_slot(self, text, seq_lens, golden_intent, n_predicts=1):\n",
        "        word_tensor, _ = self.__embedding(text)\n",
        "        embed_intent = self.__intent_embedding(golden_intent)\n",
        "\n",
        "        lstm_hiddens = self.__encoder(word_tensor, seq_lens)\n",
        "        attention_hiddens = self.__attention(word_tensor, seq_lens)\n",
        "        hiddens = torch.cat([attention_hiddens, lstm_hiddens], dim=1)\n",
        "\n",
        "        pred_slot = self.__slot_decoder(\n",
        "            hiddens, seq_lens, extra_input=embed_intent\n",
        "        )\n",
        "        _, slot_index = pred_slot.topk(n_predicts, dim=-1)\n",
        "\n",
        "        # Just predict single slot value.\n",
        "        return slot_index.cpu().data.numpy().tolist()\n",
        "\n",
        "\n",
        "class EmbeddingCollection(nn.Module):\n",
        "    \"\"\"\n",
        "    Provide word vector and position vector encoding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, max_len=5000):\n",
        "        super(EmbeddingCollection, self).__init__()\n",
        "\n",
        "        self.__input_dim = input_dim\n",
        "        # Here embedding_dim must be an even embedding.\n",
        "        self.__embedding_dim = embedding_dim\n",
        "        self.__max_len = max_len\n",
        "\n",
        "        # Word vector encoder.\n",
        "        self.__embedding_layer = nn.Embedding(\n",
        "            self.__input_dim, self.__embedding_dim\n",
        "        )\n",
        "\n",
        "        # Position vector encoder.\n",
        "        # self.__position_layer = torch.zeros(self.__max_len, self.__embedding_dim)\n",
        "        # position = torch.arange(0, self.__max_len).unsqueeze(1)\n",
        "        # div_term = torch.exp(torch.arange(0, self.__embedding_dim, 2) *\n",
        "        #                      (-math.log(10000.0) / self.__embedding_dim))\n",
        "\n",
        "        # Sine wave curve design.\n",
        "        # self.__position_layer[:, 0::2] = torch.sin(position * div_term)\n",
        "        # self.__position_layer[:, 1::2] = torch.cos(position * div_term)\n",
        "        #\n",
        "        # self.__position_layer = self.__position_layer.unsqueeze(0)\n",
        "        # self.register_buffer('pe', self.__position_layer)\n",
        "\n",
        "    def forward(self, input_x):\n",
        "        # Get word vector encoding.\n",
        "        embedding_x = self.__embedding_layer(input_x)\n",
        "\n",
        "        # Get position encoding.\n",
        "        # position_x = Variable(self.pe[:, :input_x.size(1)], requires_grad=False)\n",
        "\n",
        "        # Board-casting principle.\n",
        "        return embedding_x, embedding_x\n",
        "\n",
        "\n",
        "class LSTMEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder structure based on bidirectional LSTM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, dropout_rate):\n",
        "        super(LSTMEncoder, self).__init__()\n",
        "\n",
        "        # Parameter recording.\n",
        "        self.__embedding_dim = embedding_dim\n",
        "        self.__hidden_dim = hidden_dim // 2\n",
        "        self.__dropout_rate = dropout_rate\n",
        "\n",
        "        # Network attributes.\n",
        "        self.__dropout_layer = nn.Dropout(self.__dropout_rate)\n",
        "        self.__lstm_layer = nn.LSTM(\n",
        "            input_size=self.__embedding_dim,\n",
        "            hidden_size=self.__hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=self.__dropout_rate,\n",
        "            num_layers=1\n",
        "        )\n",
        "\n",
        "    def forward(self, embedded_text, seq_lens):\n",
        "        \"\"\" Forward process for LSTM Encoder.\n",
        "        (batch_size, max_sent_len)\n",
        "        -> (batch_size, max_sent_len, word_dim)\n",
        "        -> (batch_size, max_sent_len, hidden_dim)\n",
        "        -> (total_word_num, hidden_dim)\n",
        "        :param embedded_text: padded and embedded input text.\n",
        "        :param seq_lens: is the length of original input text.\n",
        "        :return: is encoded word hidden vectors.\n",
        "        \"\"\"\n",
        "\n",
        "        # Padded_text should be instance of LongTensor.\n",
        "        dropout_text = self.__dropout_layer(embedded_text)\n",
        "\n",
        "        # Pack and Pad process for input of variable length.\n",
        "        packed_text = pack_padded_sequence(dropout_text, seq_lens, batch_first=True)\n",
        "        lstm_hiddens, (h_last, c_last) = self.__lstm_layer(packed_text)\n",
        "        padded_hiddens, _ = pad_packed_sequence(lstm_hiddens, batch_first=True)\n",
        "\n",
        "        return torch.cat([padded_hiddens[i][:seq_lens[i], :] for i in range(0, len(seq_lens))], dim=0)\n",
        "\n",
        "\n",
        "class LSTMDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Decoder structure based on unidirectional LSTM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate, embedding_dim=None, extra_dim=None):\n",
        "        \"\"\" Construction function for Decoder.\n",
        "        :param input_dim: input dimension of Decoder. In fact, it's encoder hidden size.\n",
        "        :param hidden_dim: hidden dimension of iterative LSTM.\n",
        "        :param output_dim: output dimension of Decoder. In fact, it's total number of intent or slot.\n",
        "        :param dropout_rate: dropout rate of network which is only useful for embedding.\n",
        "        :param embedding_dim: if it's not None, the input and output are relevant.\n",
        "        :param extra_dim: if it's not None, the decoder receives information tensors.\n",
        "        \"\"\"\n",
        "\n",
        "        super(LSTMDecoder, self).__init__()\n",
        "\n",
        "        self.__input_dim = input_dim\n",
        "        self.__hidden_dim = hidden_dim\n",
        "        self.__output_dim = output_dim\n",
        "        self.__dropout_rate = dropout_rate\n",
        "        self.__embedding_dim = embedding_dim\n",
        "        self.__extra_dim = extra_dim\n",
        "\n",
        "        # If embedding_dim is not None, the output and input\n",
        "        # of this structure is relevant.\n",
        "        if self.__embedding_dim is not None:\n",
        "            self.__embedding_layer = nn.Embedding(output_dim, embedding_dim)\n",
        "            self.__init_tensor = nn.Parameter(\n",
        "                torch.randn(1, self.__embedding_dim),\n",
        "                requires_grad=True\n",
        "            )\n",
        "\n",
        "        # Make sure the input dimension of iterative LSTM.\n",
        "        if self.__extra_dim is not None and self.__embedding_dim is not None:\n",
        "            lstm_input_dim = self.__input_dim + self.__extra_dim + self.__embedding_dim\n",
        "        elif self.__extra_dim is not None:\n",
        "            lstm_input_dim = self.__input_dim + self.__extra_dim\n",
        "        elif self.__embedding_dim is not None:\n",
        "            lstm_input_dim = self.__input_dim + self.__embedding_dim\n",
        "        else:\n",
        "            lstm_input_dim = self.__input_dim\n",
        "\n",
        "        # Network parameter definition.\n",
        "        self.__dropout_layer = nn.Dropout(self.__dropout_rate)\n",
        "        self.__lstm_layer = nn.LSTM(\n",
        "            input_size=lstm_input_dim,\n",
        "            hidden_size=self.__hidden_dim,\n",
        "            batch_first=True,\n",
        "            bidirectional=False,\n",
        "            dropout=self.__dropout_rate,\n",
        "            num_layers=1\n",
        "        )\n",
        "        self.__linear_layer = nn.Linear(\n",
        "            self.__hidden_dim,\n",
        "            self.__output_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, encoded_hiddens, seq_lens, forced_input=None, extra_input=None):\n",
        "        \"\"\" Forward process for decoder.\n",
        "        :param encoded_hiddens: is encoded hidden tensors produced by encoder.\n",
        "        :param seq_lens: is a list containing lengths of sentence.\n",
        "        :param forced_input: is truth values of label, provided by teacher forcing.\n",
        "        :param extra_input: comes from another decoder as information tensor.\n",
        "        :return: is distribution of prediction labels.\n",
        "        \"\"\"\n",
        "\n",
        "        # Concatenate information tensor if possible.\n",
        "        if extra_input is not None:\n",
        "            input_tensor = torch.cat([encoded_hiddens, extra_input], dim=1)\n",
        "        else:\n",
        "            input_tensor = encoded_hiddens\n",
        "\n",
        "        output_tensor_list, sent_start_pos = [], 0\n",
        "        if self.__embedding_dim is None or forced_input is not None:\n",
        "\n",
        "            for sent_i in range(0, len(seq_lens)):\n",
        "                sent_end_pos = sent_start_pos + seq_lens[sent_i]\n",
        "\n",
        "                # Segment input hidden tensors.\n",
        "                seg_hiddens = input_tensor[sent_start_pos: sent_end_pos, :]\n",
        "\n",
        "                if self.__embedding_dim is not None and forced_input is not None:\n",
        "                    if seq_lens[sent_i] > 1:\n",
        "                        seg_forced_input = forced_input[sent_start_pos: sent_end_pos]\n",
        "                        seg_forced_tensor = self.__embedding_layer(seg_forced_input).view(seq_lens[sent_i], -1)\n",
        "                        seg_prev_tensor = torch.cat([self.__init_tensor, seg_forced_tensor[:-1, :]], dim=0)\n",
        "                    else:\n",
        "                        seg_prev_tensor = self.__init_tensor\n",
        "\n",
        "                    # Concatenate forced target tensor.\n",
        "                    combined_input = torch.cat([seg_hiddens, seg_prev_tensor], dim=1)\n",
        "                else:\n",
        "                    combined_input = seg_hiddens\n",
        "                dropout_input = self.__dropout_layer(combined_input)\n",
        "\n",
        "                lstm_out, _ = self.__lstm_layer(dropout_input.view(1, seq_lens[sent_i], -1))\n",
        "                linear_out = self.__linear_layer(lstm_out.view(seq_lens[sent_i], -1))\n",
        "\n",
        "                output_tensor_list.append(linear_out)\n",
        "                sent_start_pos = sent_end_pos\n",
        "        else:\n",
        "            for sent_i in range(0, len(seq_lens)):\n",
        "                prev_tensor = self.__init_tensor\n",
        "\n",
        "                # It's necessary to remember h and c state\n",
        "                # when output prediction every single step.\n",
        "                last_h, last_c = None, None\n",
        "\n",
        "                sent_end_pos = sent_start_pos + seq_lens[sent_i]\n",
        "                for word_i in range(sent_start_pos, sent_end_pos):\n",
        "                    seg_input = input_tensor[[word_i], :]\n",
        "                    combined_input = torch.cat([seg_input, prev_tensor], dim=1)\n",
        "                    dropout_input = self.__dropout_layer(combined_input).view(1, 1, -1)\n",
        "\n",
        "                    if last_h is None and last_c is None:\n",
        "                        lstm_out, (last_h, last_c) = self.__lstm_layer(dropout_input)\n",
        "                    else:\n",
        "                        lstm_out, (last_h, last_c) = self.__lstm_layer(dropout_input, (last_h, last_c))\n",
        "\n",
        "                    lstm_out = self.__linear_layer(lstm_out.view(1, -1))\n",
        "                    output_tensor_list.append(lstm_out)\n",
        "\n",
        "                    _, index = lstm_out.topk(1, dim=1)\n",
        "                    prev_tensor = self.__embedding_layer(index).view(1, -1)\n",
        "                sent_start_pos = sent_end_pos\n",
        "\n",
        "        return torch.cat(output_tensor_list, dim=0)\n",
        "\n",
        "\n",
        "class QKVAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention mechanism based on Query-Key-Value architecture. And\n",
        "    especially, when query == key == value, it's self-attention.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, query_dim, key_dim, value_dim, hidden_dim, output_dim, dropout_rate):\n",
        "        super(QKVAttention, self).__init__()\n",
        "\n",
        "        # Record hyper-parameters.\n",
        "        self.__query_dim = query_dim\n",
        "        self.__key_dim = key_dim\n",
        "        self.__value_dim = value_dim\n",
        "        self.__hidden_dim = hidden_dim\n",
        "        self.__output_dim = output_dim\n",
        "        self.__dropout_rate = dropout_rate\n",
        "\n",
        "        # Declare network structures.\n",
        "        self.__query_layer = nn.Linear(self.__query_dim, self.__hidden_dim)\n",
        "        self.__key_layer = nn.Linear(self.__key_dim, self.__hidden_dim)\n",
        "        self.__value_layer = nn.Linear(self.__value_dim, self.__output_dim)\n",
        "        self.__dropout_layer = nn.Dropout(p=self.__dropout_rate)\n",
        "\n",
        "    def forward(self, input_query, input_key, input_value):\n",
        "        \"\"\" The forward propagation of attention.\n",
        "        Here we require the first dimension of input key\n",
        "        and value are equal.\n",
        "        :param input_query: is query tensor, (n, d_q)\n",
        "        :param input_key:  is key tensor, (m, d_k)\n",
        "        :param input_value:  is value tensor, (m, d_v)\n",
        "        :return: attention based tensor, (n, d_h)\n",
        "        \"\"\"\n",
        "\n",
        "        # Linear transform to fine-tune dimension.\n",
        "        linear_query = self.__query_layer(input_query)\n",
        "        linear_key = self.__key_layer(input_key)\n",
        "        linear_value = self.__value_layer(input_value)\n",
        "\n",
        "        score_tensor = F.softmax(torch.matmul(\n",
        "            linear_query,\n",
        "            linear_key.transpose(-2, -1)\n",
        "        ) / math.sqrt(self.__hidden_dim), dim=-1)\n",
        "        forced_tensor = torch.matmul(score_tensor, linear_value)\n",
        "        forced_tensor = self.__dropout_layer(forced_tensor)\n",
        "\n",
        "        return forced_tensor\n",
        "\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate):\n",
        "        super(SelfAttention, self).__init__()\n",
        "\n",
        "        # Record parameters.\n",
        "        self.__input_dim = input_dim\n",
        "        self.__hidden_dim = hidden_dim\n",
        "        self.__output_dim = output_dim\n",
        "        self.__dropout_rate = dropout_rate\n",
        "\n",
        "        # Record network parameters.\n",
        "        self.__dropout_layer = nn.Dropout(self.__dropout_rate)\n",
        "        self.__attention_layer = QKVAttention(\n",
        "            self.__input_dim, self.__input_dim, self.__input_dim,\n",
        "            self.__hidden_dim, self.__output_dim, self.__dropout_rate\n",
        "        )\n",
        "\n",
        "    def forward(self, input_x, seq_lens):\n",
        "        dropout_x = self.__dropout_layer(input_x)\n",
        "        attention_x = self.__attention_layer(\n",
        "            dropout_x, dropout_x, dropout_x\n",
        "        )\n",
        "\n",
        "        flat_x = torch.cat(\n",
        "            [attention_x[i][:seq_lens[i], :] for\n",
        "             i in range(0, len(seq_lens))], dim=0\n",
        "        )\n",
        "        return flat_x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlQtNpuDjcY0"
      },
      "source": [
        "Dataset Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWbBX_Tyzhyi",
        "outputId": "f3452cd9-404d-4bd9-e65c-bb033bf2cdd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: ordered-set\n",
            "Successfully installed ordered-set-4.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ordered-set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlZFpVp9zXLd"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from collections import Counter\n",
        "from collections import OrderedDict\n",
        "from ordered_set import OrderedSet\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class Alphabet(object):\n",
        "    \"\"\"\n",
        "    Storage and serialization a set of elements.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name, if_use_pad, if_use_unk):\n",
        "\n",
        "        self.__name = name\n",
        "        self.__if_use_pad = if_use_pad\n",
        "        self.__if_use_unk = if_use_unk\n",
        "\n",
        "        self.__index2instance = OrderedSet()\n",
        "        self.__instance2index = OrderedDict()\n",
        "\n",
        "        # Counter Object record the frequency\n",
        "        # of element occurs in raw text.\n",
        "        self.__counter = Counter()\n",
        "\n",
        "        if if_use_pad:\n",
        "            self.__sign_pad = \"<PAD>\"\n",
        "            self.add_instance(self.__sign_pad)\n",
        "        if if_use_unk:\n",
        "            self.__sign_unk = \"<UNK>\"\n",
        "            self.add_instance(self.__sign_unk)\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return self.__name\n",
        "\n",
        "    def add_instance(self, instance):\n",
        "        \"\"\" Add instances to alphabet.\n",
        "        1, We support any iterative data structure which\n",
        "        contains elements of str type.\n",
        "        2, We will count added instances that will influence\n",
        "        the serialization of unknown instance.\n",
        "        :param instance: is given instance or a list of it.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(instance, (list, tuple)):\n",
        "            for element in instance:\n",
        "                self.add_instance(element)\n",
        "            return\n",
        "\n",
        "        # We only support elements of str type.\n",
        "        assert isinstance(instance, str)\n",
        "\n",
        "        # count the frequency of instances.\n",
        "        self.__counter[instance] += 1\n",
        "\n",
        "        if instance not in self.__index2instance:\n",
        "            self.__instance2index[instance] = len(self.__index2instance)\n",
        "            self.__index2instance.append(instance)\n",
        "\n",
        "    def get_index(self, instance):\n",
        "        \"\"\" Serialize given instance and return.\n",
        "        For unknown words, the return index of alphabet\n",
        "        depends on variable self.__use_unk:\n",
        "            1, If True, then return the index of \"<UNK>\";\n",
        "            2, If False, then return the index of the\n",
        "            element that hold max frequency in training data.\n",
        "        :param instance: is given instance or a list of it.\n",
        "        :return: is the serialization of query instance.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(instance, (list, tuple)):\n",
        "            return [self.get_index(elem) for elem in instance]\n",
        "\n",
        "        assert isinstance(instance, str)\n",
        "\n",
        "        try:\n",
        "            return self.__instance2index[instance]\n",
        "        except KeyError:\n",
        "            if self.__if_use_unk:\n",
        "                return self.__instance2index[self.__sign_unk]\n",
        "            else:\n",
        "                max_freq_item = self.__counter.most_common(1)[0][0]\n",
        "                return self.__instance2index[max_freq_item]\n",
        "\n",
        "    def get_instance(self, index):\n",
        "        \"\"\" Get corresponding instance of query index.\n",
        "        if index is invalid, then throws exception.\n",
        "        :param index: is query index, possibly iterable.\n",
        "        :return: is corresponding instance.\n",
        "        \"\"\"\n",
        "\n",
        "        if isinstance(index, list):\n",
        "            return [self.get_instance(elem) for elem in index]\n",
        "\n",
        "        return self.__index2instance[index]\n",
        "\n",
        "    def save_content(self, dir_path):\n",
        "        \"\"\" Save the content of alphabet to files.\n",
        "        There are two kinds of saved files:\n",
        "            1, The first is a list file, elements are\n",
        "            sorted by the frequency of occurrence.\n",
        "            2, The second is a dictionary file, elements\n",
        "            are sorted by it serialized index.\n",
        "        :param dir_path: is the directory path to save object.\n",
        "        \"\"\"\n",
        "\n",
        "        # Check if dir_path exists.\n",
        "        if not os.path.exists(dir_path):\n",
        "            os.mkdir(dir_path)\n",
        "\n",
        "        list_path = os.path.join(dir_path, self.__name + \"_list.txt\")\n",
        "        with open(list_path, 'w') as fw:\n",
        "            for element, frequency in self.__counter.most_common():\n",
        "                fw.write(element + '\\t' + str(frequency) + '\\n')\n",
        "\n",
        "        dict_path = os.path.join(dir_path, self.__name + \"_dict.txt\")\n",
        "        with open(dict_path, 'w') as fw:\n",
        "            for index, element in enumerate(self.__index2instance):\n",
        "                fw.write(element + '\\t' + str(index) + '\\n')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.__index2instance)\n",
        "\n",
        "    def __str__(self):\n",
        "        return 'Alphabet {} contains about {} words: \\n\\t{}'.format(self.name, len(self), self.__index2instance)\n",
        "\n",
        "\n",
        "class TorchDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Helper class implementing torch.utils.data.Dataset to\n",
        "    instantiate DataLoader which deliveries data batch.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, text, slot, intent):\n",
        "        self.__text = text\n",
        "        self.__slot = slot\n",
        "        self.__intent = intent\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.__text[index], self.__slot[index], self.__intent[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Pre-check to avoid bug.\n",
        "        assert len(self.__text) == len(self.__slot)\n",
        "        assert len(self.__text) == len(self.__intent)\n",
        "\n",
        "        return len(self.__text)\n",
        "\n",
        "\n",
        "class DatasetManager(object):\n",
        "\n",
        "    def __init__(self, args):\n",
        "\n",
        "        # Instantiate alphabet objects.\n",
        "        self.__word_alphabet = Alphabet('word', if_use_pad=True, if_use_unk=True)\n",
        "        self.__slot_alphabet = Alphabet('slot', if_use_pad=False, if_use_unk=False)\n",
        "        self.__intent_alphabet = Alphabet('intent', if_use_pad=False, if_use_unk=False)\n",
        "\n",
        "        # Record the raw text of dataset.\n",
        "        self.__text_word_data = {}\n",
        "        self.__text_slot_data = {}\n",
        "        self.__text_intent_data = {}\n",
        "\n",
        "        # Record the serialization of dataset.\n",
        "        self.__digit_word_data = {}\n",
        "        self.__digit_slot_data = {}\n",
        "        self.__digit_intent_data = {}\n",
        "\n",
        "        self.__args = args\n",
        "\n",
        "    @property\n",
        "    def test_sentence(self):\n",
        "        return deepcopy(self.__text_word_data['test'])\n",
        "\n",
        "    @property\n",
        "    def word_alphabet(self):\n",
        "        return deepcopy(self.__word_alphabet)\n",
        "\n",
        "    @property\n",
        "    def slot_alphabet(self):\n",
        "        return deepcopy(self.__slot_alphabet)\n",
        "\n",
        "    @property\n",
        "    def intent_alphabet(self):\n",
        "        return deepcopy(self.__intent_alphabet)\n",
        "\n",
        "    @property\n",
        "    def num_epoch(self):\n",
        "        return self.__args.num_epoch\n",
        "\n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return self.__args.batch_size\n",
        "\n",
        "    @property\n",
        "    def learning_rate(self):\n",
        "        return self.__args.learning_rate\n",
        "\n",
        "    @property\n",
        "    def l2_penalty(self):\n",
        "        return self.__args.l2_penalty\n",
        "\n",
        "    @property\n",
        "    def save_dir(self):\n",
        "        return self.__args.save_dir\n",
        "\n",
        "    @property\n",
        "    def intent_forcing_rate(self):\n",
        "        return self.__args.intent_forcing_rate\n",
        "\n",
        "    @property\n",
        "    def slot_forcing_rate(self):\n",
        "        return self.__args.slot_forcing_rate\n",
        "\n",
        "    def show_summary(self):\n",
        "        \"\"\"\n",
        "        :return: show summary of dataset, training parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        print(\"Training parameters are listed as follows:\\n\")\n",
        "\n",
        "        print('\\tnumber of train sample:                    {};'.format(len(self.__text_word_data['train'])))\n",
        "        print('\\tnumber of dev sample:                      {};'.format(len(self.__text_word_data['dev'])))\n",
        "        print('\\tnumber of test sample:                     {};'.format(len(self.__text_word_data['test'])))\n",
        "        print('\\tnumber of epoch:\t\t\t\t\t\t    {};'.format(self.num_epoch))\n",
        "        print('\\tbatch size:\t\t\t\t\t\t\t    {};'.format(self.batch_size))\n",
        "        print('\\tlearning rate:\t\t\t\t\t\t\t    {};'.format(self.learning_rate))\n",
        "        print('\\trandom seed:\t\t\t\t\t\t\t    {};'.format(self.__args.random_state))\n",
        "        print('\\trate of l2 penalty:\t\t\t\t\t    {};'.format(self.l2_penalty))\n",
        "        print('\\trate of dropout in network:                {};'.format(self.__args.dropout_rate))\n",
        "        print('\\tteacher forcing rate(slot)\t\t    \t\t{};'.format(self.slot_forcing_rate))\n",
        "        print('\\tteacher forcing rate(intent):\t\t    \t{};'.format(self.intent_forcing_rate))\n",
        "\n",
        "        print(\"\\nEnd of parameters show. Save dir: {}.\\n\\n\".format(self.save_dir))\n",
        "\n",
        "    def quick_build(self):\n",
        "        \"\"\"\n",
        "        Convenient function to instantiate a dataset object.\n",
        "        \"\"\"\n",
        "\n",
        "        train_path = os.path.join(self.__args.data_dir, 'train.txt')\n",
        "        dev_path = os.path.join(self.__args.data_dir, 'dev.txt')\n",
        "        test_path = os.path.join(self.__args.data_dir, 'test.txt')\n",
        "\n",
        "        self.add_file(train_path, 'train', if_train_file=True)\n",
        "        self.add_file(dev_path, 'dev', if_train_file=False)\n",
        "        self.add_file(test_path, 'test', if_train_file=False)\n",
        "\n",
        "        # Check if save path exists.\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.mkdir(self.save_dir)\n",
        "\n",
        "        alphabet_dir = os.path.join(self.__args.save_dir, \"alphabet\")\n",
        "        self.__word_alphabet.save_content(alphabet_dir)\n",
        "        self.__slot_alphabet.save_content(alphabet_dir)\n",
        "        self.__intent_alphabet.save_content(alphabet_dir)\n",
        "\n",
        "    def get_dataset(self, data_name, is_digital):\n",
        "        \"\"\" Get dataset of given unique name.\n",
        "        :param data_name: is name of stored dataset.\n",
        "        :param is_digital: make sure if want serialized data.\n",
        "        :return: the required dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        if is_digital:\n",
        "            return self.__digit_word_data[data_name], \\\n",
        "                   self.__digit_slot_data[data_name], \\\n",
        "                   self.__digit_intent_data[data_name]\n",
        "        else:\n",
        "            return self.__text_word_data[data_name], \\\n",
        "                   self.__text_slot_data[data_name], \\\n",
        "                   self.__text_intent_data[data_name]\n",
        "\n",
        "    def add_file(self, file_path, data_name, if_train_file):\n",
        "        text, slot, intent = self.__read_file(file_path)\n",
        "\n",
        "        if if_train_file:\n",
        "            self.__word_alphabet.add_instance(text)\n",
        "            self.__slot_alphabet.add_instance(slot)\n",
        "            self.__intent_alphabet.add_instance(intent)\n",
        "\n",
        "        # Record the raw text of dataset.\n",
        "        self.__text_word_data[data_name] = text\n",
        "        self.__text_slot_data[data_name] = slot\n",
        "        self.__text_intent_data[data_name] = intent\n",
        "\n",
        "        # Serialize raw text and stored it.\n",
        "        self.__digit_word_data[data_name] = self.__word_alphabet.get_index(text)\n",
        "        if if_train_file:\n",
        "            self.__digit_slot_data[data_name] = self.__slot_alphabet.get_index(slot)\n",
        "            self.__digit_intent_data[data_name] = self.__intent_alphabet.get_index(intent)\n",
        "\n",
        "    @staticmethod\n",
        "    def __read_file(file_path):\n",
        "        \"\"\" Read data file of given path.\n",
        "        :param file_path: path of data file.\n",
        "        :return: list of sentence, list of slot and list of intent.\n",
        "        \"\"\"\n",
        "\n",
        "        texts, slots, intents = [], [], []\n",
        "        text, slot = [], []\n",
        "\n",
        "        with open(file_path, 'r') as fr:\n",
        "            for line in fr.readlines():\n",
        "                items = line.strip().split()\n",
        "\n",
        "                if len(items) == 1:\n",
        "                    texts.append(text)\n",
        "                    slots.append(slot)\n",
        "                    intents.append(items)\n",
        "\n",
        "                    # clear buffer lists.\n",
        "                    text, slot = [], []\n",
        "\n",
        "                elif len(items) == 2:\n",
        "                    text.append(items[0].strip())\n",
        "                    slot.append(items[1].strip())\n",
        "\n",
        "        return texts, slots, intents\n",
        "\n",
        "    def batch_delivery(self, data_name, batch_size=None, is_digital=True, shuffle=True):\n",
        "        if batch_size is None:\n",
        "            batch_size = self.batch_size\n",
        "\n",
        "        if is_digital:\n",
        "            text = self.__digit_word_data[data_name]\n",
        "            slot = self.__digit_slot_data[data_name]\n",
        "            intent = self.__digit_intent_data[data_name]\n",
        "        else:\n",
        "            text = self.__text_word_data[data_name]\n",
        "            slot = self.__text_slot_data[data_name]\n",
        "            intent = self.__text_intent_data[data_name]\n",
        "        dataset = TorchDataset(text, slot, intent)\n",
        "\n",
        "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=self.__collate_fn)\n",
        "\n",
        "    @staticmethod\n",
        "    def add_padding(texts, items=None, digital=True):\n",
        "        len_list = [len(text) for text in texts]\n",
        "        max_len = max(len_list)\n",
        "\n",
        "        # Get sorted index of len_list.\n",
        "        sorted_index = np.argsort(len_list)[::-1]\n",
        "\n",
        "        trans_texts, seq_lens, trans_items = [], [], None\n",
        "        if items is not None:\n",
        "            trans_items = [[] for _ in range(0, len(items))]\n",
        "\n",
        "        for index in sorted_index:\n",
        "            seq_lens.append(deepcopy(len_list[index]))\n",
        "            trans_texts.append(deepcopy(texts[index]))\n",
        "            if digital:\n",
        "                trans_texts[-1].extend([0] * (max_len - len_list[index]))\n",
        "            else:\n",
        "                trans_texts[-1].extend(['<PAD>'] * (max_len - len_list[index]))\n",
        "\n",
        "            # This required specific if padding after sorting.\n",
        "            if items is not None:\n",
        "                for item, (o_item, required) in zip(trans_items, items):\n",
        "                    item.append(deepcopy(o_item[index]))\n",
        "                    if required:\n",
        "                        if digital:\n",
        "                            item[-1].extend([0] * (max_len - len_list[index]))\n",
        "                        else:\n",
        "                            item[-1].extend(['<PAD>'] * (max_len - len_list[index]))\n",
        "\n",
        "        if items is not None:\n",
        "            return trans_texts, trans_items, seq_lens, sorted_index\n",
        "        else:\n",
        "            return trans_texts, seq_lens, sorted_index\n",
        "\n",
        "    @staticmethod\n",
        "    def __collate_fn(batch):\n",
        "        \"\"\"\n",
        "        helper function to instantiate a DataLoader Object.\n",
        "        \"\"\"\n",
        "\n",
        "        n_entity = len(batch[0])\n",
        "        modified_batch = [[] for _ in range(0, n_entity)]\n",
        "\n",
        "        for idx in range(0, len(batch)):\n",
        "            for jdx in range(0, n_entity):\n",
        "                modified_batch[jdx].append(batch[idx][jdx])\n",
        "\n",
        "        return modified_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z0DBg963_G7"
      },
      "source": [
        "#Data Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8SfUReGMYw2"
      },
      "source": [
        "Miu Lab Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-1uoNiWMR-J"
      },
      "outputs": [],
      "source": [
        "\n",
        "# compute f1 score is modified from conlleval.pl\n",
        "def __startOfChunk(prevTag, tag, prevTagType, tagType, chunkStart=False):\n",
        "\tif prevTag == 'B' and tag == 'B':\n",
        "\t\tchunkStart = True\n",
        "\tif prevTag == 'I' and tag == 'B':\n",
        "\t\tchunkStart = True\n",
        "\tif prevTag == 'O' and tag == 'B':\n",
        "\t\tchunkStart = True\n",
        "\tif prevTag == 'O' and tag == 'I':\n",
        "\t\tchunkStart = True\n",
        "\n",
        "\tif prevTag == 'E' and tag == 'E':\n",
        "\t\tchunkStart = True\n",
        "\tif prevTag == 'E' and tag == 'I':\n",
        "\t\tchunkStart = True\n",
        "\tif prevTag == 'O' and tag == 'E':\n",
        "\t\tchunkStart = True\n",
        "\tif prevTag == 'O' and tag == 'I':\n",
        "\t\tchunkStart = True\n",
        "\n",
        "\tif tag != 'O' and tag != '.' and prevTagType != tagType:\n",
        "\t\tchunkStart = True\n",
        "\treturn chunkStart\n",
        "\n",
        "\n",
        "def __endOfChunk(prevTag, tag, prevTagType, tagType, chunkEnd=False):\n",
        "\tif prevTag == 'B' and tag == 'B':\n",
        "\t\tchunkEnd = True\n",
        "\tif prevTag == 'B' and tag == 'O':\n",
        "\t\tchunkEnd = True\n",
        "\tif prevTag == 'I' and tag == 'B':\n",
        "\t\tchunkEnd = True\n",
        "\tif prevTag == 'I' and tag == 'O':\n",
        "\t\tchunkEnd = True\n",
        "\n",
        "\tif prevTag == 'E' and tag == 'E':\n",
        "\t\tchunkEnd = True\n",
        "\tif prevTag == 'E' and tag == 'I':\n",
        "\t\tchunkEnd = True\n",
        "\tif prevTag == 'E' and tag == 'O':\n",
        "\t\tchunkEnd = True\n",
        "\tif prevTag == 'I' and tag == 'O':\n",
        "\t\tchunkEnd = True\n",
        "\n",
        "\tif prevTag != 'O' and prevTag != '.' and prevTagType != tagType:\n",
        "\t\tchunkEnd = True\n",
        "\treturn chunkEnd\n",
        "\n",
        "\n",
        "def __splitTagType(tag):\n",
        "\ts = tag.split('-')\n",
        "\tif len(s) > 2 or len(s) == 0:\n",
        "\t\traise ValueError('tag format wrong. it must be B-xxx.xxx')\n",
        "\tif len(s) == 1:\n",
        "\t\ttag = s[0]\n",
        "\t\ttagType = \"\"\n",
        "\telse:\n",
        "\t\ttag = s[0]\n",
        "\t\ttagType = s[1]\n",
        "\treturn tag, tagType\n",
        "\n",
        "\n",
        "def computeF1Score(correct_slots, pred_slots):\n",
        "\tcorrectChunk = {}\n",
        "\tcorrectChunkCnt = 0.0\n",
        "\tfoundCorrect = {}\n",
        "\tfoundCorrectCnt = 0.0\n",
        "\tfoundPred = {}\n",
        "\tfoundPredCnt = 0.0\n",
        "\tcorrectTags = 0.0\n",
        "\ttokenCount = 0.0\n",
        "\tfor correct_slot, pred_slot in zip(correct_slots, pred_slots):\n",
        "\t\tinCorrect = False\n",
        "\t\tlastCorrectTag = 'O'\n",
        "\t\tlastCorrectType = ''\n",
        "\t\tlastPredTag = 'O'\n",
        "\t\tlastPredType = ''\n",
        "\t\tfor c, p in zip(correct_slot, pred_slot):\n",
        "\t\t\tcorrectTag, correctType = __splitTagType(c)\n",
        "\t\t\tpredTag, predType = __splitTagType(p)\n",
        "\n",
        "\t\t\tif inCorrect == True:\n",
        "\t\t\t\tif __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n",
        "\t\t\t\t\t__endOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n",
        "\t\t\t\t\t(lastCorrectType == lastPredType):\n",
        "\t\t\t\t\tinCorrect = False\n",
        "\t\t\t\t\tcorrectChunkCnt += 1.0\n",
        "\t\t\t\t\tif lastCorrectType in correctChunk:\n",
        "\t\t\t\t\t\tcorrectChunk[lastCorrectType] += 1.0\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tcorrectChunk[lastCorrectType] = 1.0\n",
        "\t\t\t\telif __endOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) != \\\n",
        "\t\t\t\t\t__endOfChunk(lastPredTag, predTag, lastPredType, predType) or \\\n",
        "\t\t\t\t\t(correctType != predType):\n",
        "\t\t\t\t\tinCorrect = False\n",
        "\n",
        "\t\t\tif __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True and \\\n",
        "\t\t\t\t__startOfChunk(lastPredTag, predTag, lastPredType, predType) == True and \\\n",
        "\t\t\t\t(correctType == predType):\n",
        "\t\t\t\tinCorrect = True\n",
        "\n",
        "\t\t\tif __startOfChunk(lastCorrectTag, correctTag, lastCorrectType, correctType) == True:\n",
        "\t\t\t\tfoundCorrectCnt += 1\n",
        "\t\t\t\tif correctType in foundCorrect:\n",
        "\t\t\t\t\tfoundCorrect[correctType] += 1.0\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tfoundCorrect[correctType] = 1.0\n",
        "\n",
        "\t\t\tif __startOfChunk(lastPredTag, predTag, lastPredType, predType) == True:\n",
        "\t\t\t\tfoundPredCnt += 1.0\n",
        "\t\t\t\tif predType in foundPred:\n",
        "\t\t\t\t\tfoundPred[predType] += 1.0\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tfoundPred[predType] = 1.0\n",
        "\n",
        "\t\t\tif correctTag == predTag and correctType == predType:\n",
        "\t\t\t\tcorrectTags += 1.0\n",
        "\n",
        "\t\t\ttokenCount += 1.0\n",
        "\n",
        "\t\t\tlastCorrectTag = correctTag\n",
        "\t\t\tlastCorrectType = correctType\n",
        "\t\t\tlastPredTag = predTag\n",
        "\t\t\tlastPredType = predType\n",
        "\n",
        "\t\tif inCorrect == True:\n",
        "\t\t\tcorrectChunkCnt += 1.0\n",
        "\t\t\tif lastCorrectType in correctChunk:\n",
        "\t\t\t\tcorrectChunk[lastCorrectType] += 1.0\n",
        "\t\t\telse:\n",
        "\t\t\t\tcorrectChunk[lastCorrectType] = 1.0\n",
        "\n",
        "\tif foundPredCnt > 0:\n",
        "\t\tprecision = 1.0 * correctChunkCnt / foundPredCnt\n",
        "\telse:\n",
        "\t\tprecision = 0\n",
        "\n",
        "\tif foundCorrectCnt > 0:\n",
        "\t\trecall = 1.0 * correctChunkCnt / foundCorrectCnt\n",
        "\telse:\n",
        "\t\trecall = 0\n",
        "\n",
        "\tif (precision + recall) > 0:\n",
        "\t\tf1 = (2.0 * precision * recall) / (precision + recall)\n",
        "\telse:\n",
        "\t\tf1 = 0\n",
        "\n",
        "\treturn f1, precision, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLAI6KjJMdux"
      },
      "source": [
        "Data Processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Wkx8PcMhw7",
        "outputId": "f3e7fa71-1ea5-4a79-8a36-1073f25c0a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXSse07YsAmi",
        "outputId": "12d9bf23-3311-4998-b53a-7ea2c6dfbf1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = './data.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zipper:\n",
        "  zipper.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aHw-UZkMjIB"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "# Utils functions copied from Slot-gated model, origin url:\n",
        "# \thttps://github.com/MiuLab/SlotGated-SLU/blob/master/utils.py\n",
        "# from utils import miulab\n",
        "\n",
        "\n",
        "class Processor(object):\n",
        "\n",
        "    def __init__(self, dataset, model, batch_size):\n",
        "        self.__dataset = dataset\n",
        "        self.__model = model\n",
        "        self.__batch_size = batch_size\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            time_start = time.time()\n",
        "            self.__model = self.__model.cuda()\n",
        "\n",
        "            time_con = time.time() - time_start\n",
        "            print(\"The model has been loaded into GPU and cost {:.6f} seconds.\\n\".format(time_con))\n",
        "\n",
        "        self.__criterion = nn.NLLLoss()\n",
        "        self.__optimizer = optim.Adam(\n",
        "            self.__model.parameters(), lr=self.__dataset.learning_rate,\n",
        "            weight_decay=self.__dataset.l2_penalty\n",
        "        )\n",
        "\n",
        "    def train(self):\n",
        "        best_dev_slot = 0.0\n",
        "        best_dev_intent = 0.0\n",
        "        best_dev_sent = 0.0\n",
        "\n",
        "        dataloader = self.__dataset.batch_delivery('train')\n",
        "        for epoch in range(0, self.__dataset.num_epoch):\n",
        "            total_slot_loss, total_intent_loss = 0.0, 0.0\n",
        "\n",
        "            time_start = time.time()\n",
        "            self.__model.train()\n",
        "\n",
        "            for text_batch, slot_batch, intent_batch in tqdm(dataloader, ncols=50):\n",
        "                padded_text, [sorted_slot, sorted_intent], seq_lens, _ = self.__dataset.add_padding(\n",
        "                    text_batch, [(slot_batch, False), (intent_batch, False)]\n",
        "                )\n",
        "                sorted_intent = [item * num for item, num in zip(sorted_intent, seq_lens)]\n",
        "                sorted_intent = list(Evaluator.expand_list(sorted_intent))\n",
        "\n",
        "                text_var = Variable(torch.LongTensor(padded_text))\n",
        "                slot_var = Variable(torch.LongTensor(list(Evaluator.expand_list(sorted_slot))))\n",
        "                intent_var = Variable(torch.LongTensor(sorted_intent))\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    text_var = text_var.cuda()\n",
        "                    slot_var = slot_var.cuda()\n",
        "                    intent_var = intent_var.cuda()\n",
        "\n",
        "                random_slot, random_intent = random.random(), random.random()\n",
        "                if random_slot < self.__dataset.slot_forcing_rate and \\\n",
        "                        random_intent < self.__dataset.intent_forcing_rate:\n",
        "                    slot_out, intent_out = self.__model(\n",
        "                        text_var, seq_lens, forced_slot=slot_var, forced_intent=intent_var\n",
        "                    )\n",
        "                elif random_slot < self.__dataset.slot_forcing_rate:\n",
        "                    slot_out, intent_out = self.__model(\n",
        "                        text_var, seq_lens, forced_slot=slot_var\n",
        "                    )\n",
        "                elif random_intent < self.__dataset.intent_forcing_rate:\n",
        "                    slot_out, intent_out = self.__model(\n",
        "                        text_var, seq_lens, forced_intent=intent_var\n",
        "                    )\n",
        "                else:\n",
        "                    slot_out, intent_out = self.__model(text_var, seq_lens)\n",
        "\n",
        "                slot_loss = self.__criterion(slot_out, slot_var)\n",
        "                intent_loss = self.__criterion(intent_out, intent_var)\n",
        "                batch_loss = slot_loss + intent_loss\n",
        "\n",
        "                self.__optimizer.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                self.__optimizer.step()\n",
        "\n",
        "                try:\n",
        "                    total_slot_loss += slot_loss.cpu().item()\n",
        "                    total_intent_loss += intent_loss.cpu().item()\n",
        "                except AttributeError:\n",
        "                    total_slot_loss += slot_loss.cpu().data.numpy()[0]\n",
        "                    total_intent_loss += intent_loss.cpu().data.numpy()[0]\n",
        "\n",
        "            time_con = time.time() - time_start\n",
        "            print('[Epoch {:2d}]: The total slot loss on train data is {:2.6f}, intent data is {:2.6f}, cost ' \\\n",
        "                  'about {:2.6} seconds.'.format(epoch, total_slot_loss, total_intent_loss, time_con))\n",
        "\n",
        "            change, time_start = False, time.time()\n",
        "            dev_f1_score, dev_acc, dev_sent_acc = self.estimate(if_dev=True, test_batch=self.__batch_size)\n",
        "\n",
        "            if dev_f1_score > best_dev_slot or dev_acc > best_dev_intent or dev_sent_acc > best_dev_sent:\n",
        "                test_f1, test_acc, test_sent_acc = self.estimate(if_dev=False, test_batch=self.__batch_size)\n",
        "\n",
        "                if dev_f1_score > best_dev_slot:\n",
        "                    best_dev_slot = dev_f1_score\n",
        "                if dev_acc > best_dev_intent:\n",
        "                    best_dev_intent = dev_acc\n",
        "                if dev_sent_acc > best_dev_sent:\n",
        "                    best_dev_sent = dev_sent_acc\n",
        "\n",
        "                print('\\nTest result: slot f1 score: {:.6f}, intent acc score: {:.6f}, semantic '\n",
        "                      'accuracy score: {:.6f}.'.format(test_f1, test_acc, test_sent_acc))\n",
        "\n",
        "                model_save_dir = os.path.join(self.__dataset.save_dir, \"model\")\n",
        "                if not os.path.exists(model_save_dir):\n",
        "                    os.mkdir(model_save_dir)\n",
        "\n",
        "                torch.save(self.__model, os.path.join(model_save_dir, \"model.pkl\"))\n",
        "                torch.save(self.__dataset, os.path.join(model_save_dir, 'dataset.pkl'))\n",
        "\n",
        "                time_con = time.time() - time_start\n",
        "                print('[Epoch {:2d}]: In validation process, the slot f1 score is {:2.6f}, ' \\\n",
        "                      'the intent acc is {:2.6f}, the semantic acc is {:.2f}, cost about ' \\\n",
        "                      '{:2.6f} seconds.\\n'.format(epoch, dev_f1_score, dev_acc, dev_sent_acc, time_con))\n",
        "\n",
        "    def estimate(self, if_dev, test_batch=100):\n",
        "        \"\"\"\n",
        "        Estimate the performance of model on dev or test dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        if if_dev:\n",
        "            pred_slot, real_slot, pred_intent, real_intent, _ = self.prediction(\n",
        "                self.__model, self.__dataset, \"dev\", test_batch\n",
        "            )\n",
        "        else:\n",
        "            pred_slot, real_slot, pred_intent, real_intent, _ = self.prediction(\n",
        "                self.__model, self.__dataset, \"test\", test_batch\n",
        "            )\n",
        "\n",
        "        slot_f1_socre = computeF1Score(pred_slot, real_slot)[0]\n",
        "        intent_acc = Evaluator.accuracy(pred_intent, real_intent)\n",
        "        sent_acc = Evaluator.semantic_acc(pred_slot, real_slot, pred_intent, real_intent)\n",
        "\n",
        "        return slot_f1_socre, intent_acc, sent_acc\n",
        "\n",
        "    @staticmethod\n",
        "    def validate(model_path, dataset_path, batch_size):\n",
        "        \"\"\"\n",
        "        validation will write mistaken samples to files and make scores.\n",
        "        \"\"\"\n",
        "\n",
        "        model = torch.load(model_path)\n",
        "        dataset = torch.load(dataset_path)\n",
        "\n",
        "        # Get the sentence list in test dataset.\n",
        "        sent_list = dataset.test_sentence\n",
        "\n",
        "        pred_slot, real_slot, exp_pred_intent, real_intent, pred_intent = Processor.prediction(\n",
        "            model, dataset, \"test\", batch_size\n",
        "        )\n",
        "\n",
        "        # To make sure the directory for save error prediction.\n",
        "        mistake_dir = os.path.join(dataset.save_dir, \"error\")\n",
        "        if not os.path.exists(mistake_dir):\n",
        "            os.mkdir(mistake_dir)\n",
        "\n",
        "        slot_file_path = os.path.join(mistake_dir, \"slot.txt\")\n",
        "        intent_file_path = os.path.join(mistake_dir, \"intent.txt\")\n",
        "        both_file_path = os.path.join(mistake_dir, \"both.txt\")\n",
        "\n",
        "        # Write those sample with mistaken slot prediction.\n",
        "        with open(slot_file_path, 'w') as fw:\n",
        "            for w_list, r_slot_list, p_slot_list in zip(sent_list, real_slot, pred_slot):\n",
        "                if r_slot_list != p_slot_list:\n",
        "                    for w, r, p in zip(w_list, r_slot_list, p_slot_list):\n",
        "                        fw.write(w + '\\t' + r + '\\t' + p + '\\n')\n",
        "                    fw.write('\\n')\n",
        "\n",
        "        # Write those sample with mistaken intent prediction.\n",
        "        with open(intent_file_path, 'w') as fw:\n",
        "            for w_list, p_intent_list, r_intent, p_intent in zip(sent_list, pred_intent, real_intent, exp_pred_intent):\n",
        "                if p_intent != r_intent:\n",
        "                    for w, p in zip(w_list, p_intent_list):\n",
        "                        fw.write(w + '\\t' + p + '\\n')\n",
        "                    fw.write(r_intent + '\\t' + p_intent + '\\n\\n')\n",
        "\n",
        "        # Write those sample both have intent and slot errors.\n",
        "        with open(both_file_path, 'w') as fw:\n",
        "            for w_list, r_slot_list, p_slot_list, p_intent_list, r_intent, p_intent in \\\n",
        "                    zip(sent_list, real_slot, pred_slot, pred_intent, real_intent, exp_pred_intent):\n",
        "\n",
        "                if r_slot_list != p_slot_list or r_intent != p_intent:\n",
        "                    for w, r_slot, p_slot, p_intent_ in zip(w_list, r_slot_list, p_slot_list, p_intent_list):\n",
        "                        fw.write(w + '\\t' + r_slot + '\\t' + p_slot + '\\t' + p_intent_ + '\\n')\n",
        "                    fw.write(r_intent + '\\t' + p_intent + '\\n\\n')\n",
        "\n",
        "        slot_f1 = computeF1Score(pred_slot, real_slot)[0]\n",
        "        intent_acc = Evaluator.accuracy(exp_pred_intent, real_intent)\n",
        "        sent_acc = Evaluator.semantic_acc(pred_slot, real_slot, exp_pred_intent, real_intent)\n",
        "\n",
        "        return slot_f1, intent_acc, sent_acc\n",
        "\n",
        "    @staticmethod\n",
        "    def prediction(model, dataset, mode, batch_size):\n",
        "        model.eval()\n",
        "\n",
        "        if mode == \"dev\":\n",
        "            dataloader = dataset.batch_delivery('dev', batch_size=batch_size, shuffle=False, is_digital=False)\n",
        "        elif mode == \"test\":\n",
        "            dataloader = dataset.batch_delivery('test', batch_size=batch_size, shuffle=False, is_digital=False)\n",
        "        else:\n",
        "            raise Exception(\"Argument error! mode belongs to {\\\"dev\\\", \\\"test\\\"}.\")\n",
        "\n",
        "        pred_slot, real_slot = [], []\n",
        "        pred_intent, real_intent = [], []\n",
        "\n",
        "        for text_batch, slot_batch, intent_batch in tqdm(dataloader, ncols=50):\n",
        "            padded_text, [sorted_slot, sorted_intent], seq_lens, sorted_index = dataset.add_padding(\n",
        "                text_batch, [(slot_batch, False), (intent_batch, False)], digital=False\n",
        "            )\n",
        "            # Because it's a visualization bug, in valid time, it doesn't matter\n",
        "            # Only in test time will it need to restore\n",
        "            if mode == 'test':\n",
        "                tmp_r_slot = [[] for _ in range(len(sorted_index))]\n",
        "                for i in range(len(sorted_index)):\n",
        "                    tmp_r_slot[sorted_index[i]] = sorted_slot[i]\n",
        "                sorted_slot = tmp_r_slot\n",
        "                tmp_intent = [[] for _ in range(len(sorted_index))]\n",
        "                for i in range(len(sorted_index)):\n",
        "                    tmp_intent[sorted_index[i]] = sorted_intent[i]\n",
        "                sorted_intent = tmp_intent\n",
        "            \n",
        "            real_slot.extend(sorted_slot)\n",
        "            real_intent.extend(list(Evaluator.expand_list(sorted_intent)))\n",
        "\n",
        "            digit_text = dataset.word_alphabet.get_index(padded_text)\n",
        "            var_text = Variable(torch.LongTensor(digit_text))\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                var_text = var_text.cuda()\n",
        "\n",
        "            slot_idx, intent_idx = model(var_text, seq_lens, n_predicts=1)\n",
        "            nested_slot = Evaluator.nested_list([list(Evaluator.expand_list(slot_idx))], seq_lens)[0]\n",
        "            \n",
        "            if mode == 'test':\n",
        "                tmp_r_slot = [[] for _ in range(len(sorted_index))]\n",
        "                for i in range(len(sorted_index)):\n",
        "                    tmp_r_slot[sorted_index[i]] = nested_slot[i]\n",
        "                nested_slot = tmp_r_slot\n",
        "            \n",
        "            pred_slot.extend(dataset.slot_alphabet.get_instance(nested_slot))\n",
        "            nested_intent = Evaluator.nested_list([list(Evaluator.expand_list(intent_idx))], seq_lens)[0]\n",
        "            \n",
        "            if mode == 'test':\n",
        "                tmp_intent = [[] for _ in range(len(sorted_index))]\n",
        "                for i in range(len(sorted_index)):\n",
        "                    tmp_intent[sorted_index[i]] = nested_intent[i]\n",
        "                nested_intent = tmp_intent\n",
        "            \n",
        "            pred_intent.extend(dataset.intent_alphabet.get_instance(nested_intent))\n",
        "\n",
        "        exp_pred_intent = Evaluator.max_freq_predict(pred_intent)\n",
        "        return pred_slot, real_slot, exp_pred_intent, real_intent, pred_intent\n",
        "\n",
        "\n",
        "class Evaluator(object):\n",
        "\n",
        "    @staticmethod\n",
        "    def semantic_acc(pred_slot, real_slot, pred_intent, real_intent):\n",
        "        \"\"\"\n",
        "        Compute the accuracy based on the whole predictions of\n",
        "        given sentence, including slot and intent.\n",
        "        \"\"\"\n",
        "\n",
        "        total_count, correct_count = 0.0, 0.0\n",
        "        for p_slot, r_slot, p_intent, r_intent in zip(pred_slot, real_slot, pred_intent, real_intent):\n",
        "\n",
        "            if p_slot == r_slot and p_intent == r_intent:\n",
        "                correct_count += 1.0\n",
        "            total_count += 1.0\n",
        "\n",
        "        return 1.0 * correct_count / total_count\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(pred_list, real_list):\n",
        "        \"\"\"\n",
        "        Get accuracy measured by predictions and ground-trues.\n",
        "        \"\"\"\n",
        "\n",
        "        pred_array = np.array(list(Evaluator.expand_list(pred_list)))\n",
        "        real_array = np.array(list(Evaluator.expand_list(real_list)))\n",
        "        return (pred_array == real_array).sum() * 1.0 / len(pred_array)\n",
        "\n",
        "    @staticmethod\n",
        "    def f1_score(pred_list, real_list):\n",
        "        \"\"\"\n",
        "        Get F1 score measured by predictions and ground-trues.\n",
        "        \"\"\"\n",
        "\n",
        "        tp, fp, fn = 0.0, 0.0, 0.0\n",
        "        for i in range(len(pred_list)):\n",
        "            seg = set()\n",
        "            result = [elem.strip() for elem in pred_list[i]]\n",
        "            target = [elem.strip() for elem in real_list[i]]\n",
        "\n",
        "            j = 0\n",
        "            while j < len(target):\n",
        "                cur = target[j]\n",
        "                if cur[0] == 'B':\n",
        "                    k = j + 1\n",
        "                    while k < len(target):\n",
        "                        str_ = target[k]\n",
        "                        if not (str_[0] == 'I' and cur[1:] == str_[1:]):\n",
        "                            break\n",
        "                        k = k + 1\n",
        "                    seg.add((cur, j, k - 1))\n",
        "                    j = k - 1\n",
        "                j = j + 1\n",
        "\n",
        "            tp_ = 0\n",
        "            j = 0\n",
        "            while j < len(result):\n",
        "                cur = result[j]\n",
        "                if cur[0] == 'B':\n",
        "                    k = j + 1\n",
        "                    while k < len(result):\n",
        "                        str_ = result[k]\n",
        "                        if not (str_[0] == 'I' and cur[1:] == str_[1:]):\n",
        "                            break\n",
        "                        k = k + 1\n",
        "                    if (cur, j, k - 1) in seg:\n",
        "                        tp_ += 1\n",
        "                    else:\n",
        "                        fp += 1\n",
        "                    j = k - 1\n",
        "                j = j + 1\n",
        "\n",
        "            fn += len(seg) - tp_\n",
        "            tp += tp_\n",
        "\n",
        "        p = tp / (tp + fp) if tp + fp != 0 else 0\n",
        "        r = tp / (tp + fn) if tp + fn != 0 else 0\n",
        "        return 2 * p * r / (p + r) if p + r != 0 else 0\n",
        "\n",
        "    \"\"\"\n",
        "    Max frequency prediction. \n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def max_freq_predict(sample):\n",
        "        predict = []\n",
        "        for items in sample:\n",
        "            predict.append(Counter(items).most_common(1)[0][0])\n",
        "        return predict\n",
        "\n",
        "    @staticmethod\n",
        "    def exp_decay_predict(sample, decay_rate=0.8):\n",
        "        predict = []\n",
        "        for items in sample:\n",
        "            item_dict = {}\n",
        "            curr_weight = 1.0\n",
        "            for item in items[::-1]:\n",
        "                item_dict[item] = item_dict.get(item, 0) + curr_weight\n",
        "                curr_weight *= decay_rate\n",
        "            predict.append(sorted(item_dict.items(), key=lambda x_: x_[1])[-1][0])\n",
        "        return predict\n",
        "\n",
        "    @staticmethod\n",
        "    def expand_list(nested_list):\n",
        "        for item in nested_list:\n",
        "            if isinstance(item, (list, tuple)):\n",
        "                for sub_item in Evaluator.expand_list(item):\n",
        "                    yield sub_item\n",
        "            else:\n",
        "                yield item\n",
        "\n",
        "    @staticmethod\n",
        "    def nested_list(items, seq_lens):\n",
        "        num_items = len(items)\n",
        "        trans_items = [[] for _ in range(0, num_items)]\n",
        "\n",
        "        count = 0\n",
        "        for jdx in range(0, len(seq_lens)):\n",
        "            for idx in range(0, num_items):\n",
        "                trans_items[idx].append(items[idx][count:count + seq_lens[jdx]])\n",
        "            count += seq_lens[jdx]\n",
        "\n",
        "        return trans_items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBFYSyHug3Gy"
      },
      "source": [
        "#Training and *Testing*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eocvUBNfg4ta",
        "outputId": "a32ccb3e-3516-4777-fcb7-ead890d26859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training parameters are listed as follows:\n",
            "\n",
            "\tnumber of train sample:                    13093;\n",
            "\tnumber of dev sample:                      700;\n",
            "\tnumber of test sample:                     700;\n",
            "\tnumber of epoch:\t\t\t\t\t\t    60;\n",
            "\tbatch size:\t\t\t\t\t\t\t    32;\n",
            "\tlearning rate:\t\t\t\t\t\t\t    0.001;\n",
            "\trandom seed:\t\t\t\t\t\t\t    42;\n",
            "\trate of l2 penalty:\t\t\t\t\t    1e-06;\n",
            "\trate of dropout in network:                0.4;\n",
            "\tteacher forcing rate(slot)\t\t    \t\t0.9;\n",
            "\tteacher forcing rate(intent):\t\t    \t0.9;\n",
            "\n",
            "End of parameters show. Save dir: ./save/.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters are listed as follows:\n",
            "\n",
            "\tnumber of word:                            11436;\n",
            "\tnumber of slot:                            72;\n",
            "\tnumber of intent:\t\t\t\t\t\t    8;\n",
            "\tword embedding dimension:\t\t\t\t    64;\n",
            "\tencoder hidden dimension:\t\t\t\t    256;\n",
            "\tdimension of intent embedding:\t\t    \t8;\n",
            "\tdimension of slot embedding:\t\t\t    32;\n",
            "\tdimension of slot decoder hidden:  \t    64;\n",
            "\tdimension of intent decoder hidden:        64;\n",
            "\thidden dimension of self-attention:        1024;\n",
            "\toutput dimension of self-attention:        128;\n",
            "\n",
            "End of parameters show. Now training begins.\n",
            "\n",
            "\n",
            "The model has been loaded into GPU and cost 10.872604 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:50<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  0]: The total slot loss on train data is 721.501590, intent data is 158.676579, cost about 110.603 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.22it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.353345, intent acc score: 0.921429, semantic accuracy score: 0.137143.\n",
            "[Epoch  0]: In validation process, the slot f1 score is 0.365826, the intent acc is 0.947143, the semantic acc is 0.13, cost about 20.090941 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:46<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  1]: The total slot loss on train data is 334.197000, intent data is 35.673624, cost about 106.062 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.540166, intent acc score: 0.941429, semantic accuracy score: 0.307143.\n",
            "[Epoch  1]: In validation process, the slot f1 score is 0.540585, the intent acc is 0.968571, the semantic acc is 0.30, cost about 20.099024 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:51<00:00,  3.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  2]: The total slot loss on train data is 231.592994, intent data is 24.736686, cost about 111.647 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n",
            "100%|█████████████| 22/22 [00:10<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.626493, intent acc score: 0.945714, semantic accuracy score: 0.397143.\n",
            "[Epoch  2]: In validation process, the slot f1 score is 0.635607, the intent acc is 0.967143, the semantic acc is 0.43, cost about 20.322247 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:51<00:00,  3.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  3]: The total slot loss on train data is 183.006018, intent data is 17.969332, cost about 111.273 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.679328, intent acc score: 0.957143, semantic accuracy score: 0.460000.\n",
            "[Epoch  3]: In validation process, the slot f1 score is 0.697456, the intent acc is 0.974286, the semantic acc is 0.49, cost about 20.115864 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:45<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  4]: The total slot loss on train data is 146.621829, intent data is 15.461864, cost about 105.185 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.727273, intent acc score: 0.955714, semantic accuracy score: 0.511429.\n",
            "[Epoch  4]: In validation process, the slot f1 score is 0.740535, the intent acc is 0.975714, the semantic acc is 0.54, cost about 20.160764 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:44<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  5]: The total slot loss on train data is 121.331229, intent data is 14.867283, cost about 104.659 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.26it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.762116, intent acc score: 0.961429, semantic accuracy score: 0.552857.\n",
            "[Epoch  5]: In validation process, the slot f1 score is 0.775146, the intent acc is 0.980000, the semantic acc is 0.60, cost about 19.985311 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:46<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  6]: The total slot loss on train data is 110.041636, intent data is 11.840156, cost about 106.702 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.789766, intent acc score: 0.965714, semantic accuracy score: 0.588571.\n",
            "[Epoch  6]: In validation process, the slot f1 score is 0.804796, the intent acc is 0.978571, the semantic acc is 0.64, cost about 20.019022 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:51<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  7]: The total slot loss on train data is 94.751687, intent data is 9.656486, cost about 111.144 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.799778, intent acc score: 0.967143, semantic accuracy score: 0.592857.\n",
            "[Epoch  7]: In validation process, the slot f1 score is 0.808013, the intent acc is 0.977143, the semantic acc is 0.64, cost about 20.340294 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:42<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  8]: The total slot loss on train data is 80.706998, intent data is 8.584927, cost about 102.158 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.824148, intent acc score: 0.962857, semantic accuracy score: 0.641429.\n",
            "[Epoch  8]: In validation process, the slot f1 score is 0.833704, the intent acc is 0.975714, the semantic acc is 0.67, cost about 19.946093 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:50<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch  9]: The total slot loss on train data is 76.019436, intent data is 9.494223, cost about 110.635 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.840796, intent acc score: 0.964286, semantic accuracy score: 0.672857.\n",
            "[Epoch  9]: In validation process, the slot f1 score is 0.851194, the intent acc is 0.972857, the semantic acc is 0.69, cost about 19.768708 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:49<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10]: The total slot loss on train data is 67.672500, intent data is 6.949698, cost about 109.027 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.22it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.853976, intent acc score: 0.965714, semantic accuracy score: 0.700000.\n",
            "[Epoch 10]: In validation process, the slot f1 score is 0.867537, the intent acc is 0.978571, the semantic acc is 0.72, cost about 20.285174 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:48<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11]: The total slot loss on train data is 60.310879, intent data is 7.140717, cost about 108.597 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.22it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.871880, intent acc score: 0.968571, semantic accuracy score: 0.724286.\n",
            "[Epoch 11]: In validation process, the slot f1 score is 0.879066, the intent acc is 0.977143, the semantic acc is 0.74, cost about 20.221208 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:47<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12]: The total slot loss on train data is 57.334761, intent data is 7.299071, cost about 107.885 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.28it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.874480, intent acc score: 0.968571, semantic accuracy score: 0.731429.\n",
            "[Epoch 12]: In validation process, the slot f1 score is 0.890985, the intent acc is 0.978571, the semantic acc is 0.76, cost about 19.875094 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:47<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 13]: The total slot loss on train data is 49.207945, intent data is 7.088587, cost about 107.45 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.34it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.883463, intent acc score: 0.971429, semantic accuracy score: 0.751429.\n",
            "[Epoch 13]: In validation process, the slot f1 score is 0.899444, the intent acc is 0.981429, the semantic acc is 0.77, cost about 19.393787 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:55<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 14]: The total slot loss on train data is 49.850666, intent data is 5.077366, cost about 115.145 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.33it/s]\n",
            "100%|███████████| 410/410 [01:55<00:00,  3.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 15]: The total slot loss on train data is 44.611841, intent data is 6.456925, cost about 115.28 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.896169, intent acc score: 0.972857, semantic accuracy score: 0.768571.\n",
            "[Epoch 15]: In validation process, the slot f1 score is 0.907067, the intent acc is 0.977143, the semantic acc is 0.80, cost about 20.128321 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:49<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 16]: The total slot loss on train data is 40.819092, intent data is 5.881781, cost about 109.575 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.15it/s]\n",
            "100%|█████████████| 22/22 [00:10<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.906215, intent acc score: 0.970000, semantic accuracy score: 0.787143.\n",
            "[Epoch 16]: In validation process, the slot f1 score is 0.911470, the intent acc is 0.980000, the semantic acc is 0.80, cost about 20.880525 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:47<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 17]: The total slot loss on train data is 38.207580, intent data is 3.954089, cost about 107.291 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.20it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.909749, intent acc score: 0.968571, semantic accuracy score: 0.792857.\n",
            "[Epoch 17]: In validation process, the slot f1 score is 0.917339, the intent acc is 0.975714, the semantic acc is 0.81, cost about 20.453187 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:47<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 18]: The total slot loss on train data is 35.907763, intent data is 3.835534, cost about 107.067 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.21it/s]\n",
            "100%|███████████| 410/410 [01:41<00:00,  4.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 19]: The total slot loss on train data is 33.652992, intent data is 2.879071, cost about 101.777 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.18it/s]\n",
            "100%|███████████| 410/410 [01:47<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 20]: The total slot loss on train data is 32.110528, intent data is 3.710571, cost about 107.91 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.19it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.913237, intent acc score: 0.971429, semantic accuracy score: 0.802857.\n",
            "[Epoch 20]: In validation process, the slot f1 score is 0.921323, the intent acc is 0.982857, the semantic acc is 0.82, cost about 20.492850 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:49<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 21]: The total slot loss on train data is 30.368431, intent data is 3.583328, cost about 109.877 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|███████████| 410/410 [01:44<00:00,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 22]: The total slot loss on train data is 28.344486, intent data is 3.248837, cost about 104.624 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|███████████| 410/410 [01:50<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 23]: The total slot loss on train data is 26.204995, intent data is 3.272958, cost about 110.305 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.916829, intent acc score: 0.971429, semantic accuracy score: 0.808571.\n",
            "[Epoch 23]: In validation process, the slot f1 score is 0.923973, the intent acc is 0.980000, the semantic acc is 0.82, cost about 20.355923 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:43<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 24]: The total slot loss on train data is 23.642161, intent data is 3.853690, cost about 103.791 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|███████████| 410/410 [01:48<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 25]: The total slot loss on train data is 23.847163, intent data is 3.083782, cost about 108.333 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|███████████| 410/410 [01:43<00:00,  3.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 26]: The total slot loss on train data is 20.345588, intent data is 1.939785, cost about 103.957 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.921367, intent acc score: 0.975714, semantic accuracy score: 0.821429.\n",
            "[Epoch 26]: In validation process, the slot f1 score is 0.923931, the intent acc is 0.980000, the semantic acc is 0.83, cost about 20.041036 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:45<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 27]: The total slot loss on train data is 21.921766, intent data is 1.970621, cost about 105.347 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.920723, intent acc score: 0.972857, semantic accuracy score: 0.815714.\n",
            "[Epoch 27]: In validation process, the slot f1 score is 0.929068, the intent acc is 0.977143, the semantic acc is 0.84, cost about 19.879598 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:40<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 28]: The total slot loss on train data is 19.298249, intent data is 2.384318, cost about 100.165 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.26it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.921879, intent acc score: 0.977143, semantic accuracy score: 0.820000.\n",
            "[Epoch 28]: In validation process, the slot f1 score is 0.930297, the intent acc is 0.980000, the semantic acc is 0.84, cost about 19.988143 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:44<00:00,  3.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 29]: The total slot loss on train data is 19.613438, intent data is 1.757897, cost about 104.303 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n",
            "100%|█████████████| 22/22 [00:10<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.921667, intent acc score: 0.975714, semantic accuracy score: 0.827143.\n",
            "[Epoch 29]: In validation process, the slot f1 score is 0.928968, the intent acc is 0.978571, the semantic acc is 0.84, cost about 20.363727 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:46<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 30]: The total slot loss on train data is 18.384991, intent data is 2.937123, cost about 106.806 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.18it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.922563, intent acc score: 0.974286, semantic accuracy score: 0.827143.\n",
            "[Epoch 30]: In validation process, the slot f1 score is 0.938004, the intent acc is 0.985714, the semantic acc is 0.86, cost about 20.527671 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:45<00:00,  3.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 31]: The total slot loss on train data is 16.839741, intent data is 2.036799, cost about 105.859 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|███████████| 410/410 [01:46<00:00,  3.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 32]: The total slot loss on train data is 16.273274, intent data is 1.864745, cost about 106.698 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.21it/s]\n",
            "100%|███████████| 410/410 [01:52<00:00,  3.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 33]: The total slot loss on train data is 16.855866, intent data is 2.076992, cost about 112.189 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n",
            "100%|███████████| 410/410 [01:45<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 34]: The total slot loss on train data is 15.125492, intent data is 1.825337, cost about 105.643 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.28it/s]\n",
            "100%|███████████| 410/410 [01:44<00:00,  3.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 35]: The total slot loss on train data is 15.779326, intent data is 2.291062, cost about 104.371 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.29it/s]\n",
            "100%|███████████| 410/410 [01:48<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 36]: The total slot loss on train data is 15.038873, intent data is 2.376457, cost about 108.82 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.20it/s]\n",
            "100%|███████████| 410/410 [01:47<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 37]: The total slot loss on train data is 14.132990, intent data is 1.724939, cost about 107.084 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.22it/s]\n",
            "100%|███████████| 410/410 [01:40<00:00,  4.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 38]: The total slot loss on train data is 12.280323, intent data is 1.751095, cost about 100.679 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.28it/s]\n",
            "100%|███████████| 410/410 [01:50<00:00,  3.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 39]: The total slot loss on train data is 13.693544, intent data is 2.153094, cost about 110.599 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|███████████| 410/410 [01:49<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 40]: The total slot loss on train data is 13.117422, intent data is 3.716976, cost about 109.529 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.17it/s]\n",
            "100%|█████████████| 22/22 [00:10<00:00,  2.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.929327, intent acc score: 0.975714, semantic accuracy score: 0.841429.\n",
            "[Epoch 40]: In validation process, the slot f1 score is 0.938889, the intent acc is 0.987143, the semantic acc is 0.85, cost about 20.897372 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:43<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 41]: The total slot loss on train data is 12.243162, intent data is 1.568930, cost about 103.46 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|███████████| 410/410 [01:44<00:00,  3.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 42]: The total slot loss on train data is 11.609278, intent data is 0.685262, cost about 104.778 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.28it/s]\n",
            "100%|███████████| 410/410 [01:49<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 43]: The total slot loss on train data is 11.666523, intent data is 1.851873, cost about 109.043 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.928552, intent acc score: 0.975714, semantic accuracy score: 0.841429.\n",
            "[Epoch 43]: In validation process, the slot f1 score is 0.938923, the intent acc is 0.984286, the semantic acc is 0.85, cost about 20.125399 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:52<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 44]: The total slot loss on train data is 11.149129, intent data is 1.137767, cost about 112.788 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.22it/s]\n",
            "100%|███████████| 410/410 [01:50<00:00,  3.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 45]: The total slot loss on train data is 10.247085, intent data is 1.609829, cost about 110.278 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.22it/s]\n",
            "100%|███████████| 410/410 [01:53<00:00,  3.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 46]: The total slot loss on train data is 10.228552, intent data is 1.289276, cost about 113.835 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|███████████| 410/410 [01:51<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 47]: The total slot loss on train data is 10.657460, intent data is 2.644018, cost about 111.085 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.17it/s]\n",
            "100%|███████████| 410/410 [01:49<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 48]: The total slot loss on train data is 10.376407, intent data is 1.344694, cost about 110.008 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.27it/s]\n",
            "100%|███████████| 410/410 [01:48<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 49]: The total slot loss on train data is 9.512226, intent data is 0.738157, cost about 108.198 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.26it/s]\n",
            "100%|███████████| 410/410 [01:46<00:00,  3.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 50]: The total slot loss on train data is 9.119884, intent data is 0.635967, cost about 106.936 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.19it/s]\n",
            "100%|███████████| 410/410 [01:47<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 51]: The total slot loss on train data is 9.398875, intent data is 1.007757, cost about 107.96 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n",
            "100%|███████████| 410/410 [01:43<00:00,  3.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 52]: The total slot loss on train data is 8.342137, intent data is 1.310828, cost about 103.557 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.23it/s]\n",
            "100%|███████████| 410/410 [01:42<00:00,  3.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 53]: The total slot loss on train data is 8.313315, intent data is 1.846063, cost about 102.788 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:10<00:00,  2.19it/s]\n",
            "100%|███████████| 410/410 [01:49<00:00,  3.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 54]: The total slot loss on train data is 8.664076, intent data is 0.907485, cost about 109.903 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.32it/s]\n",
            "100%|███████████| 410/410 [01:48<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 55]: The total slot loss on train data is 8.347189, intent data is 0.757896, cost about 108.225 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.31it/s]\n",
            "100%|███████████| 410/410 [01:47<00:00,  3.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 56]: The total slot loss on train data is 8.021664, intent data is 1.232511, cost about 107.494 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test result: slot f1 score: 0.932368, intent acc score: 0.978571, semantic accuracy score: 0.850000.\n",
            "[Epoch 56]: In validation process, the slot f1 score is 0.940784, the intent acc is 0.984286, the semantic acc is 0.86, cost about 19.994652 seconds.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████| 410/410 [01:45<00:00,  3.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 57]: The total slot loss on train data is 7.655802, intent data is 1.407636, cost about 105.609 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.26it/s]\n",
            "100%|███████████| 410/410 [01:49<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 58]: The total slot loss on train data is 7.760165, intent data is 1.574089, cost about 109.172 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.30it/s]\n",
            "100%|███████████| 410/410 [01:43<00:00,  3.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 59]: The total slot loss on train data is 7.968899, intent data is 1.317936, cost about 103.816 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████| 22/22 [00:09<00:00,  2.29it/s]\n",
            "100%|█████████████| 22/22 [00:09<00:00,  2.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accepted performance: (0.9323684942944614, 0.9785714285714285, 0.85) at test dataset;\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "class Object(object):\n",
        "    pass\n",
        "\n",
        "args = Object()\n",
        "# Training Params\n",
        "args.save_dir = './save/'\n",
        "args.random_state = 42\n",
        "args.batch_size = 32\n",
        "args.num_epoch = 60\n",
        "args.l2_penalty = 1e-6\n",
        "args.dropout_rate = 0.4\n",
        "args.learning_rate = 1e-3\n",
        "args.intent_forcing_rate = 0.9\n",
        "args.slot_forcing_rate = 0.9\n",
        "args.differentiable= False\n",
        "args.data_dir = './data/'\n",
        "\n",
        "# Model params\n",
        "args.word_embedding_dim = 64\n",
        "args.encoder_hidden_dim= 256\n",
        "args.intent_embedding_dim = 8\n",
        "args.slot_embedding_dim = 32\n",
        "args.slot_decoder_hidden_dim = 64\n",
        "args.intent_decoder_hidden_dim = 64\n",
        "args.attention_hidden_dim = 1024\n",
        "args.attention_output_dim = 128\n",
        "\n",
        "\n",
        "# Save training and model parameters.\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.system(\"mkdir -p \" + args.save_dir)\n",
        "\n",
        "log_path = os.path.join(args.save_dir, \"param.json\")\n",
        "\n",
        "# Fix the random seed of package random.\n",
        "random.seed(args.random_state)\n",
        "np.random.seed(args.random_state)\n",
        "\n",
        "# Fix the random seed of Pytorch when using GPU.\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(args.random_state)\n",
        "    torch.cuda.manual_seed(args.random_state)\n",
        "\n",
        "# Fix the random seed of Pytorch when using CPU.\n",
        "torch.manual_seed(args.random_state)\n",
        "torch.random.manual_seed(args.random_state)\n",
        "\n",
        "# Instantiate a dataset object.\n",
        "dataset = DatasetManager(args)\n",
        "dataset.quick_build()\n",
        "dataset.show_summary()\n",
        "\n",
        "# Instantiate a network model object.\n",
        "model = ModelManager(\n",
        "    args, len(dataset.word_alphabet),\n",
        "    len(dataset.slot_alphabet),\n",
        "    len(dataset.intent_alphabet))\n",
        "model.show_summary()\n",
        "\n",
        "# To train and evaluate the models.\n",
        "process = Processor(dataset, model, args.batch_size)\n",
        "process.train()\n",
        "\n",
        "print('\\nAccepted performance: ' + str(Processor.validate(\n",
        "    os.path.join(args.save_dir, \"model/model.pkl\"),\n",
        "    os.path.join(args.save_dir, \"model/dataset.pkl\"),\n",
        "    args.batch_size)) + \" at test dataset;\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xVu_2oQmhey"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "StackPropagation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}